{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nimport tensorflow as tf\nprint(tf.__version__)\n\n\n#from textblob import TextBlob\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\nimport warnings \nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-18T18:32:30.654276Z","iopub.execute_input":"2021-10-18T18:32:30.654518Z","iopub.status.idle":"2021-10-18T18:32:40.819757Z","shell.execute_reply.started":"2021-10-18T18:32:30.654440Z","shell.execute_reply":"2021-10-18T18:32:40.818321Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ndf_submission = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:33:24.283168Z","iopub.execute_input":"2021-10-18T18:33:24.283888Z","iopub.status.idle":"2021-10-18T18:33:24.358902Z","shell.execute_reply.started":"2021-10-18T18:33:24.283847Z","shell.execute_reply":"2021-10-18T18:33:24.358204Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Use it to reduce df memory\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:33:47.055329Z","iopub.execute_input":"2021-10-18T18:33:47.055583Z","iopub.status.idle":"2021-10-18T18:33:47.071795Z","shell.execute_reply.started":"2021-10-18T18:33:47.055555Z","shell.execute_reply":"2021-10-18T18:33:47.071146Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Reduce dataFrame memory : \n#df_train = reduce_mem_usage(df_train)\n#df_test = reduce_mem_usage(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T16:24:22.321584Z","iopub.execute_input":"2021-10-18T16:24:22.32178Z","iopub.status.idle":"2021-10-18T16:24:22.325099Z","shell.execute_reply.started":"2021-10-18T16:24:22.321757Z","shell.execute_reply":"2021-10-18T16:24:22.324416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To drop repeated tweets\ndf_train = df_train.drop_duplicates('text', keep='last')\nprint(df_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:03.483975Z","iopub.execute_input":"2021-10-18T18:34:03.484705Z","iopub.status.idle":"2021-10-18T18:34:03.505418Z","shell.execute_reply.started":"2021-10-18T18:34:03.484665Z","shell.execute_reply":"2021-10-18T18:34:03.504489Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## **Data Exploratory**","metadata":{}},{"cell_type":"markdown","source":"### 1/ **Missing values analysis**","metadata":{}},{"cell_type":"code","source":"# Missing values analysis\nprint(df_train.isnull().sum())\nprint(df_train.isna().sum().sort_values(ascending=False)/df_train.shape[0])","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:06.165467Z","iopub.execute_input":"2021-10-18T18:34:06.166016Z","iopub.status.idle":"2021-10-18T18:34:06.181910Z","shell.execute_reply.started":"2021-10-18T18:34:06.165955Z","shell.execute_reply":"2021-10-18T18:34:06.181054Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"missing_cols = ['keyword', 'location']\n\nfig, axes = plt.subplots(ncols=2, figsize=(17, 4), dpi=100)\n\nsns.barplot(x=df_train[missing_cols].isnull().sum().index, y=df_train[missing_cols].isnull().sum().values, ax=axes[0])\nsns.barplot(x=df_test[missing_cols].isnull().sum().index, y=df_test[missing_cols].isnull().sum().values, ax=axes[1])\n\naxes[0].set_ylabel('Missing Value Count', size=15, labelpad=20)\naxes[0].tick_params(axis='x', labelsize=15)\naxes[0].tick_params(axis='y', labelsize=15)\naxes[1].tick_params(axis='x', labelsize=15)\naxes[1].tick_params(axis='y', labelsize=15)\n\naxes[0].set_title('Training Set', fontsize=13)\naxes[1].set_title('Test Set', fontsize=13)\n\nplt.show()\n\nfor df in [df_train, df_test]:\n    for col in ['keyword', 'location']:\n        df[col] = df[col].fillna(f'no_{col}')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:06.511653Z","iopub.execute_input":"2021-10-18T18:34:06.512094Z","iopub.status.idle":"2021-10-18T18:34:06.818489Z","shell.execute_reply.started":"2021-10-18T18:34:06.512062Z","shell.execute_reply":"2021-10-18T18:34:06.817798Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### 2/ **Distribution analysis**","metadata":{}},{"cell_type":"code","source":"#The distribution of the target\nsns.countplot(df_train['target'])\n\n# We can see that the target is almost balanced","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:07.893968Z","iopub.execute_input":"2021-10-18T18:34:07.894527Z","iopub.status.idle":"2021-10-18T18:34:08.051450Z","shell.execute_reply.started":"2021-10-18T18:34:07.894491Z","shell.execute_reply":"2021-10-18T18:34:08.050574Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"df_train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:19.935165Z","iopub.execute_input":"2021-10-18T18:34:19.935911Z","iopub.status.idle":"2021-10-18T18:34:19.942514Z","shell.execute_reply.started":"2021-10-18T18:34:19.935873Z","shell.execute_reply":"2021-10-18T18:34:19.941671Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Distribution of unique keywords in train and test\nplt.figure(figsize=(15,40))\nprint(f'Unique keywords sum ={len(df_train.keyword.unique())}')\nprint(f'Unique keywords sum ={len(df_test.keyword.unique())}')\nsns.countplot(y=df_train['keyword'], color=(0,0,1), label='Train')\nsns.countplot(y=df_test['keyword'], color=(1,0,0), label='Test')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:30.765425Z","iopub.execute_input":"2021-10-18T18:34:30.766018Z","iopub.status.idle":"2021-10-18T18:34:35.138380Z","shell.execute_reply.started":"2021-10-18T18:34:30.765959Z","shell.execute_reply":"2021-10-18T18:34:35.137642Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Distribution of keyvalueson the target 0 / 1\n\n\n#plt.figure(figsize=(15,100))\n#sns.countplot(data=df_train, y='keyword', hue='target')\n\n\n#------------------------------------------------------------------------\n\ndf_train['target_mean'] = df_train.groupby('keyword')['target'].transform('mean')\n\nfig = plt.figure(figsize=(8, 72), dpi=100)\n\nsns.countplot(y=df_train.sort_values(by='target_mean', ascending=False)['keyword'],\n              hue=df_train.sort_values(by='target_mean', ascending=False)['target'], palette = \"BuPu\")\n\nplt.tick_params(axis='x', labelsize=15)\nplt.tick_params(axis='y', labelsize=12)\nplt.legend(loc=1)\nplt.title('Target Distribution in Keywords')\n\nplt.show()\n\ndf_train.drop(columns=['target_mean'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:42.589628Z","iopub.execute_input":"2021-10-18T18:34:42.590181Z","iopub.status.idle":"2021-10-18T18:34:46.609753Z","shell.execute_reply.started":"2021-10-18T18:34:42.590145Z","shell.execute_reply":"2021-10-18T18:34:46.608840Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"target_0 = df_train[df_train['target']==0]\ntarget_1 = df_train[df_train['target']==1]","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:46.611538Z","iopub.execute_input":"2021-10-18T18:34:46.611853Z","iopub.status.idle":"2021-10-18T18:34:46.618607Z","shell.execute_reply.started":"2021-10-18T18:34:46.611816Z","shell.execute_reply":"2021-10-18T18:34:46.617837Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#TOP 20 keywords on target 0\nplt.figure(figsize=(9,6))\nsns.countplot(y=target_0.keyword, order = target_0.keyword.value_counts().iloc[:20].index)\nplt.title('Top 20 keywords on target 0')\nplt.show()\n\n#TOP 20 keywords on target 1\nplt.figure(figsize=(9,6))\nsns.countplot(y=target_1.keyword, order = target_1.keyword.value_counts().iloc[:20].index)\nplt.title('Top 20 keywords on target 1')\nplt.show()\n\n\n# No keywords (TOP 20) are in common betweetn target 0 and target 1","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:34:49.301502Z","iopub.execute_input":"2021-10-18T18:34:49.301752Z","iopub.status.idle":"2021-10-18T18:34:49.889209Z","shell.execute_reply.started":"2021-10-18T18:34:49.301724Z","shell.execute_reply":"2021-10-18T18:34:49.888528Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Hashtag in disaster and non disaster\nfrom string import punctuation\n\ndef clean(word):\n    for p in punctuation: word = word.replace(p, '')\n    return word\n\nfrom wordcloud import WordCloud\n\ndef wc_hash(target):\n    hashtag = [clean(w[1:].lower()) for tweet in df_train[df_train.target == target].text for w in tweet.split() if '#' in w and w[0] == '#']\n    hashtag = ' '.join(hashtag)\n    my_cloud = WordCloud(background_color='white', stopwords=STOP_WORDS).generate(hashtag)\n\n    plt.subplot(1,2,target+1)\n    plt.imshow(my_cloud, interpolation='bilinear') \n    plt.axis(\"off\")\n\nplt.figure(figsize=(15,4))\nwc_hash(0)\nplt.title('Non-Disaster')\nwc_hash(1)\nplt.title('Disaster')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:09.197474Z","iopub.execute_input":"2021-10-18T18:35:09.198149Z","iopub.status.idle":"2021-10-18T18:35:10.066549Z","shell.execute_reply.started":"2021-10-18T18:35:09.198111Z","shell.execute_reply":"2021-10-18T18:35:10.065885Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Set index on data ID\ndf_train = df_train.set_index(df_train.id)\n#Drop the the column ID\ndf_train = df_train.drop('id', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:13.312609Z","iopub.execute_input":"2021-10-18T18:35:13.313423Z","iopub.status.idle":"2021-10-18T18:35:13.320355Z","shell.execute_reply.started":"2021-10-18T18:35:13.313378Z","shell.execute_reply":"2021-10-18T18:35:13.319412Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:17.775799Z","iopub.execute_input":"2021-10-18T18:35:17.776329Z","iopub.status.idle":"2021-10-18T18:35:17.791843Z","shell.execute_reply.started":"2021-10-18T18:35:17.776291Z","shell.execute_reply":"2021-10-18T18:35:17.791028Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## ****Data Preprocessing****","metadata":{"execution":{"iopub.status.busy":"2021-10-15T20:16:32.404611Z","iopub.execute_input":"2021-10-15T20:16:32.405845Z","iopub.status.idle":"2021-10-15T20:16:32.412523Z","shell.execute_reply.started":"2021-10-15T20:16:32.405789Z","shell.execute_reply":"2021-10-15T20:16:32.4114Z"}}},{"cell_type":"code","source":"#Put text on lower case\ndf_train['text'] = df_train['text'].apply(lambda x: x.lower())\ndf_test['text'] = df_test['text'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:29.333503Z","iopub.execute_input":"2021-10-18T18:35:29.333751Z","iopub.status.idle":"2021-10-18T18:35:29.344880Z","shell.execute_reply.started":"2021-10-18T18:35:29.333723Z","shell.execute_reply":"2021-10-18T18:35:29.343882Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import re\n#Remove the emails\ndf_train['text'] = df_train['text'].apply(lambda x: re.sub(r'[A-Za-z0-9+._-]+@[A-Za-z0-9+._-]+\\.[A-Za-z0-9+._-]+','', x))\ndf_test['text'] = df_test['text'].apply(lambda x: re.sub(r'[A-Za-z0-9+._-]+@[A-Za-z0-9+._-]+\\.[A-Za-z0-9+._-]+','', x))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:30.852785Z","iopub.execute_input":"2021-10-18T18:35:30.853497Z","iopub.status.idle":"2021-10-18T18:35:30.939192Z","shell.execute_reply.started":"2021-10-18T18:35:30.853457Z","shell.execute_reply":"2021-10-18T18:35:30.938420Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#Remove URLS\ndf_train['text'] = df_train['text'].apply(lambda x: re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \"\", x))\ndf_test['text'] = df_test['text'].apply(lambda x: re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \"\", x))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:31.862735Z","iopub.execute_input":"2021-10-18T18:35:31.863041Z","iopub.status.idle":"2021-10-18T18:35:32.000886Z","shell.execute_reply.started":"2021-10-18T18:35:31.863003Z","shell.execute_reply":"2021-10-18T18:35:32.000171Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Remove retweets\ndf_train['text'] = df_train['text'].apply(lambda x: re.sub('RT','',x))\ndf_test['text'] = df_test['text'].apply(lambda x: re.sub('RT','',x))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:32.103446Z","iopub.execute_input":"2021-10-18T18:35:32.103657Z","iopub.status.idle":"2021-10-18T18:35:32.145511Z","shell.execute_reply.started":"2021-10-18T18:35:32.103633Z","shell.execute_reply":"2021-10-18T18:35:32.144683Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Remove special car and punctuation\ndf_train['text'] = df_train['text'].apply(lambda x: re.sub('[^A-Z a-z 0-9]+','',x))\ndf_test['text'] = df_test['text'].apply(lambda x: re.sub('[^A-Z a-z 0-9]+','',x))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:32.561367Z","iopub.execute_input":"2021-10-18T18:35:32.561608Z","iopub.status.idle":"2021-10-18T18:35:32.621670Z","shell.execute_reply.started":"2021-10-18T18:35:32.561581Z","shell.execute_reply":"2021-10-18T18:35:32.621052Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Apostrophe Dictionary\napostrophe_dict = {\n\"ain't\": \"am not / are not\",\n\"aren't\": \"are not / am not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he had / he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he shall / he will\",\n\"he'll've\": \"he shall have / he will have\",\n\"he's\": \"he has / he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how has / how is\",\n\"i'd\": \"I had / I would\",\n\"i'd've\": \"I would have\",\n\"i'll\": \"I shall / I will\",\n\"i'll've\": \"I shall have / I will have\",\n\"i'm\": \"I am\",\n\"i've\": \"I have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it had / it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it shall / it will\",\n\"it'll've\": \"it shall have / it will have\",\n\"it's\": \"it has / it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she had / she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she shall / she will\",\n\"she'll've\": \"she shall have / she will have\",\n\"she's\": \"she has / she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so as / so is\",\n\"that'd\": \"that would / that had\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that has / that is\",\n\"there'd\": \"there had / there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there has / there is\",\n\"they'd\": \"they had / they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they shall / they will\",\n\"they'll've\": \"they shall have / they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\"we'd\": \"we had / we would\",\n\"we'd've\": \"we would have\",\n\"we'll\": \"we will\",\n\"we'll've\": \"we will have\",\n\"we're\": \"we are\",\n\"we've\": \"we have\",\n\"weren't\": \"were not\",\n\"what'll\": \"what shall / what will\",\n\"what'll've\": \"what shall have / what will have\",\n\"what're\": \"what are\",\n\"what's\": \"what has / what is\",\n\"what've\": \"what have\",\n\"when's\": \"when has / when is\",\n\"when've\": \"when have\",\n\"where'd\": \"where did\",\n\"where's\": \"where has / where is\",\n\"where've\": \"where have\",\n\"who'll\": \"who shall / who will\",\n\"who'll've\": \"who shall have / who will have\",\n\"who's\": \"who has / who is\",\n\"who've\": \"who have\",\n\"why's\": \"why has / why is\",\n\"why've\": \"why have\",\n\"will've\": \"will have\",\n\"won't\": \"will not\",\n\"won't've\": \"will not have\",\n\"would've\": \"would have\",\n\"wouldn't\": \"would not\",\n\"wouldn't've\": \"would not have\",\n\"y'all\": \"you all\",\n\"y'all'd\": \"you all would\",\n\"y'all'd've\": \"you all would have\",\n\"y'all're\": \"you all are\",\n\"y'all've\": \"you all have\",\n\"you'd\": \"you had / you would\",\n\"you'd've\": \"you would have\",\n\"you'll\": \"you shall / you will\",\n\"you'll've\": \"you shall have / you will have\",\n\"you're\": \"you are\",\n\"you've\": \"you have\"\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:37.223656Z","iopub.execute_input":"2021-10-18T18:35:37.224132Z","iopub.status.idle":"2021-10-18T18:35:37.239736Z","shell.execute_reply.started":"2021-10-18T18:35:37.224097Z","shell.execute_reply":"2021-10-18T18:35:37.238825Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#Extend contractions\ndef contractions(text, dictionary):\n    for word in text.split():\n        if word.lower() in dictionary:\n            if word.lower() in text.split():\n                text = text.replace(word, dictionary[word.lower()])\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:46.788916Z","iopub.execute_input":"2021-10-18T18:35:46.789582Z","iopub.status.idle":"2021-10-18T18:35:46.794486Z","shell.execute_reply.started":"2021-10-18T18:35:46.789541Z","shell.execute_reply":"2021-10-18T18:35:46.793664Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"df_train['text'] = df_train['text'].apply(lambda x: contractions(x,apostrophe_dict))\ndf_test['text'] = df_test['text'].apply(lambda x: contractions(x,apostrophe_dict))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:49.161472Z","iopub.execute_input":"2021-10-18T18:35:49.161725Z","iopub.status.idle":"2021-10-18T18:35:49.205321Z","shell.execute_reply.started":"2021-10-18T18:35:49.161698Z","shell.execute_reply":"2021-10-18T18:35:49.204663Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"short_word_dict = {\n\"121\": \"one to one\",\n\"a/s/l\": \"age, sex, location\",\n\"adn\": \"any day now\",\n\"afaik\": \"as far as I know\",\n\"afk\": \"away from keyboard\",\n\"aight\": \"alright\",\n\"alol\": \"actually laughing out loud\",\n\"b4\": \"before\",\n\"b4n\": \"bye for now\",\n\"bak\": \"back at the keyboard\",\n\"bf\": \"boyfriend\",\n\"bff\": \"best friends forever\",\n\"bfn\": \"bye for now\",\n\"bg\": \"big grin\",\n\"bta\": \"but then again\",\n\"btw\": \"by the way\",\n\"cid\": \"crying in disgrace\",\n\"cnp\": \"continued in my next post\",\n\"cp\": \"chat post\",\n\"cu\": \"see you\",\n\"cul\": \"see you later\",\n\"cul8r\": \"see you later\",\n\"cya\": \"bye\",\n\"cyo\": \"see you online\",\n\"dbau\": \"doing business as usual\",\n\"fud\": \"fear, uncertainty, and doubt\",\n\"fwiw\": \"for what it's worth\",\n\"fyi\": \"for your information\",\n\"g\": \"grin\",\n\"g2g\": \"got to go\",\n\"ga\": \"go ahead\",\n\"gal\": \"get a life\",\n\"gf\": \"girlfriend\",\n\"gfn\": \"gone for now\",\n\"gmbo\": \"giggling my butt off\",\n\"gmta\": \"great minds think alike\",\n\"h8\": \"hate\",\n\"hagn\": \"have a good night\",\n\"hdop\": \"help delete online predators\",\n\"hhis\": \"hanging head in shame\",\n\"iac\": \"in any case\",\n\"ianal\": \"I am not a lawyer\",\n\"ic\": \"I see\",\n\"idk\": \"I don't know\",\n\"imao\": \"in my arrogant opinion\",\n\"imnsho\": \"in my not so humble opinion\",\n\"imo\": \"in my opinion\",\n\"iow\": \"in other words\",\n\"ipn\": \"I’m posting naked\",\n\"irl\": \"in real life\",\n\"jk\": \"just kidding\",\n\"l8r\": \"later\",\n\"ld\": \"later, dude\",\n\"ldr\": \"long distance relationship\",\n\"llta\": \"lots and lots of thunderous applause\",\n\"lmao\": \"laugh my ass off\",\n\"lmirl\": \"let's meet in real life\",\n\"lol\": \"laugh out loud\",\n\"ltr\": \"longterm relationship\",\n\"lulab\": \"love you like a brother\",\n\"lulas\": \"love you like a sister\",\n\"luv\": \"love\",\n\"m/f\": \"male or female\",\n\"m8\": \"mate\",\n\"milf\": \"mother I would like to fuck\",\n\"oll\": \"online love\",\n\"omg\": \"oh my god\",\n\"otoh\": \"on the other hand\",\n\"pir\": \"parent in room\",\n\"ppl\": \"people\",\n\"r\": \"are\",\n\"rofl\": \"roll on the floor laughing\",\n\"rpg\": \"role playing games\",\n\"ru\": \"are you\",\n\"shid\": \"slaps head in disgust\",\n\"somy\": \"sick of me yet\",\n\"sot\": \"short of time\",\n\"thanx\": \"thanks\",\n\"thx\": \"thanks\",\n\"ttyl\": \"talk to you later\",\n\"u\": \"you\",\n\"ur\": \"you are\",\n\"uw\": \"you’re welcome\",\n\"wb\": \"welcome back\",\n\"wfm\": \"works for me\",\n\"wibni\": \"wouldn't it be nice if\",\n\"wtf\": \"what the fuck\",\n\"wtg\": \"way to go\",\n\"wtgp\": \"want to go private\",\n\"ym\": \"young man\",\n\"gr8\": \"great\"\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:54.341462Z","iopub.execute_input":"2021-10-18T18:35:54.341714Z","iopub.status.idle":"2021-10-18T18:35:54.357383Z","shell.execute_reply.started":"2021-10-18T18:35:54.341683Z","shell.execute_reply":"2021-10-18T18:35:54.356616Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#Extend short words\ndf_train['text'] = df_train['text'].apply(lambda x: contractions(x,short_word_dict))\ndf_test['text'] = df_test['text'].apply(lambda x: contractions(x,short_word_dict))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:56.379313Z","iopub.execute_input":"2021-10-18T18:35:56.380023Z","iopub.status.idle":"2021-10-18T18:35:56.425040Z","shell.execute_reply.started":"2021-10-18T18:35:56.379964Z","shell.execute_reply":"2021-10-18T18:35:56.424318Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#HTML Text extract\nfrom bs4 import BeautifulSoup\n\n%%time\ndf_train['text'] = df_train['text'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())\ndf_test['text'] = df_test['text'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:57.905532Z","iopub.execute_input":"2021-10-18T18:35:57.906062Z","iopub.status.idle":"2021-10-18T18:35:58.064072Z","shell.execute_reply.started":"2021-10-18T18:35:57.906023Z","shell.execute_reply":"2021-10-18T18:35:58.061789Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"#Remove stopWords\ndf_train['text'] = df_train['text'].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))\ndf_test['text'] = df_test['text'].apply(lambda x: \" \".join([t for t in x.split() if t not in STOP_WORDS]))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:35:59.245307Z","iopub.execute_input":"2021-10-18T18:35:59.245832Z","iopub.status.idle":"2021-10-18T18:35:59.289150Z","shell.execute_reply.started":"2021-10-18T18:35:59.245790Z","shell.execute_reply":"2021-10-18T18:35:59.288359Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\nprint(remove_emoji(\"OMG the forest is on fire!!! 😭😱😷\"))\n\ndf_train['text'] = df_train['text'].apply(lambda x: remove_emoji(x))\ndf_test['text'] = df_test['text'].apply(lambda x: remove_emoji(x))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:37:34.366192Z","iopub.execute_input":"2021-10-18T18:37:34.366752Z","iopub.status.idle":"2021-10-18T18:37:34.432235Z","shell.execute_reply.started":"2021-10-18T18:37:34.366715Z","shell.execute_reply":"2021-10-18T18:37:34.431409Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"#Stemming\nimport nltk\nfrom nltk.stem.porter import *\nstemmer = PorterStemmer()\ndef to_stem(x):\n    x_list = []\n    for token in x.split():\n        stems = str(stemmer.stem(token))\n        x_list.append(stems)\n    return \" \".join(x_list)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:38:18.683298Z","iopub.execute_input":"2021-10-18T18:38:18.683582Z","iopub.status.idle":"2021-10-18T18:38:18.691619Z","shell.execute_reply.started":"2021-10-18T18:38:18.683553Z","shell.execute_reply":"2021-10-18T18:38:18.690868Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_train['text_stems'] = df_train['text'].apply(lambda x: to_stem(x))\ndf_test['text_stems'] = df_test['text'].apply(lambda x: to_stem(x))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:38:23.466953Z","iopub.execute_input":"2021-10-18T18:38:23.467826Z","iopub.status.idle":"2021-10-18T18:38:25.908213Z","shell.execute_reply.started":"2021-10-18T18:38:23.467775Z","shell.execute_reply":"2021-10-18T18:38:25.907307Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#Lemmatize\nnlp = spacy.load('en_core_web_sm')\ndef lemmatize(x):\n    x_list = []\n    doc = nlp(x)\n    for token in doc:\n        lemma = str(token.lemma_)\n        x_list.append(lemma)\n    return \" \".join(x_list)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:41:56.326414Z","iopub.execute_input":"2021-10-18T18:41:56.326675Z","iopub.status.idle":"2021-10-18T18:41:56.999759Z","shell.execute_reply.started":"2021-10-18T18:41:56.326647Z","shell.execute_reply":"2021-10-18T18:41:56.999024Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"%%time\ndf_train['text_lemma'] = df_train['text'].apply(lambda x: lemmatize(x))\ndf_test['text_lemma'] = df_test['text'].apply(lambda x: lemmatize(x))","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:42:37.793169Z","iopub.execute_input":"2021-10-18T18:42:37.793861Z","iopub.status.idle":"2021-10-18T18:43:33.506091Z","shell.execute_reply.started":"2021-10-18T18:42:37.793823Z","shell.execute_reply":"2021-10-18T18:43:33.505282Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df_train.head()\n#df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:44:25.005044Z","iopub.execute_input":"2021-10-18T18:44:25.005316Z","iopub.status.idle":"2021-10-18T18:44:25.016879Z","shell.execute_reply.started":"2021-10-18T18:44:25.005285Z","shell.execute_reply":"2021-10-18T18:44:25.016213Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# If there's a GPU available...\nimport torch\nif torch.cuda.is_available():    \n\n    # Tell PyTorch to use the GPU.  \n    \n    device = torch.device('cuda')    \n\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:45:12.982849Z","iopub.execute_input":"2021-10-18T18:45:12.983389Z","iopub.status.idle":"2021-10-18T18:45:12.994663Z","shell.execute_reply.started":"2021-10-18T18:45:12.983353Z","shell.execute_reply":"2021-10-18T18:45:12.993458Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## **Modeling**","metadata":{}},{"cell_type":"code","source":"!pip install -U tensorflow_text","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:47:44.519302Z","iopub.execute_input":"2021-10-18T18:47:44.519564Z","iopub.status.idle":"2021-10-18T18:48:03.521737Z","shell.execute_reply.started":"2021-10-18T18:47:44.519536Z","shell.execute_reply":"2021-10-18T18:48:03.520827Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"!pip install -q tf-models-official","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:49:26.591599Z","iopub.execute_input":"2021-10-18T18:49:26.591873Z","iopub.status.idle":"2021-10-18T18:49:34.705487Z","shell.execute_reply.started":"2021-10-18T18:49:26.591841Z","shell.execute_reply":"2021-10-18T18:49:34.704559Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(df_train.drop(['keyword','location','target'],axis=1), df_train[['target']], test_size=0.1, stratify=df_train[['target']], random_state=0)\n\nprint('X_train shape: ', X_train.shape)\nprint('X_val shape: ', X_valid.shape)\nprint('y_train shape: ', y_train.shape)\nprint('y_val shape: ', y_valid.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:52:48.294495Z","iopub.execute_input":"2021-10-18T18:52:48.294780Z","iopub.status.idle":"2021-10-18T18:52:48.356229Z","shell.execute_reply.started":"2021-10-18T18:52:48.294747Z","shell.execute_reply":"2021-10-18T18:52:48.355400Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"y_valid","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:56:13.049363Z","iopub.execute_input":"2021-10-18T18:56:13.049903Z","iopub.status.idle":"2021-10-18T18:56:13.059473Z","shell.execute_reply.started":"2021-10-18T18:56:13.049866Z","shell.execute_reply":"2021-10-18T18:56:13.058760Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nfrom official.nlp import optimization","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:53:18.161901Z","iopub.execute_input":"2021-10-18T18:53:18.162443Z","iopub.status.idle":"2021-10-18T18:53:19.706650Z","shell.execute_reply.started":"2021-10-18T18:53:18.162390Z","shell.execute_reply":"2021-10-18T18:53:19.705961Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"batch_size = 16\nseed = 42\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train['text_lemma'].tolist(),y_train['target'].tolist())).batch(batch_size)\n#valid_ds = tf.data.Dataset.from_tensor_slices((X_valid['text'],y_valid['target'])).batch(batch_size)\n#print(train_ds)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:58:02.416098Z","iopub.execute_input":"2021-10-18T18:58:02.418171Z","iopub.status.idle":"2021-10-18T18:58:02.519679Z","shell.execute_reply.started":"2021-10-18T18:58:02.418125Z","shell.execute_reply":"2021-10-18T18:58:02.518865Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"#@title Choose a BERT model to fine-tune\n\nbert_model_name = 'bert_en_uncased_L-12_H-768_A-12'  #@param [\"bert_en_uncased_L-12_H-768_A-12\", \"bert_en_cased_L-12_H-768_A-12\", \"bert_multi_cased_L-12_H-768_A-12\", \"small_bert/bert_en_uncased_L-2_H-128_A-2\", \"small_bert/bert_en_uncased_L-2_H-256_A-4\", \"small_bert/bert_en_uncased_L-2_H-512_A-8\", \"small_bert/bert_en_uncased_L-2_H-768_A-12\", \"small_bert/bert_en_uncased_L-4_H-128_A-2\", \"small_bert/bert_en_uncased_L-4_H-256_A-4\", \"small_bert/bert_en_uncased_L-4_H-512_A-8\", \"small_bert/bert_en_uncased_L-4_H-768_A-12\", \"small_bert/bert_en_uncased_L-6_H-128_A-2\", \"small_bert/bert_en_uncased_L-6_H-256_A-4\", \"small_bert/bert_en_uncased_L-6_H-512_A-8\", \"small_bert/bert_en_uncased_L-6_H-768_A-12\", \"small_bert/bert_en_uncased_L-8_H-128_A-2\", \"small_bert/bert_en_uncased_L-8_H-256_A-4\", \"small_bert/bert_en_uncased_L-8_H-512_A-8\", \"small_bert/bert_en_uncased_L-8_H-768_A-12\", \"small_bert/bert_en_uncased_L-10_H-128_A-2\", \"small_bert/bert_en_uncased_L-10_H-256_A-4\", \"small_bert/bert_en_uncased_L-10_H-512_A-8\", \"small_bert/bert_en_uncased_L-10_H-768_A-12\", \"small_bert/bert_en_uncased_L-12_H-128_A-2\", \"small_bert/bert_en_uncased_L-12_H-256_A-4\", \"small_bert/bert_en_uncased_L-12_H-512_A-8\", \"small_bert/bert_en_uncased_L-12_H-768_A-12\", \"albert_en_base\", \"electra_small\", \"electra_base\", \"experts_pubmed\", \"experts_wiki_books\", \"talking-heads_base\"]\n\nmap_name_to_handle = {\n    'bert_en_uncased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n    'bert_en_cased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n    'bert_multi_cased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n    'albert_en_base':\n        'https://tfhub.dev/tensorflow/albert_en_base/2',\n    'electra_small':\n        'https://tfhub.dev/google/electra_small/2',\n    'electra_base':\n        'https://tfhub.dev/google/electra_base/2',\n    'experts_pubmed':\n        'https://tfhub.dev/google/experts/bert/pubmed/2',\n    'experts_wiki_books':\n        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n    'talking-heads_base':\n        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n}\n\nmap_model_to_preprocess = {\n    'bert_en_uncased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'bert_en_cased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/2',\n    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'bert_multi_cased_L-12_H-768_A-12':\n        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/2',\n    'albert_en_base':\n        'https://tfhub.dev/tensorflow/albert_en_preprocess/2',\n    'electra_small':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'electra_base':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'experts_pubmed':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'experts_wiki_books':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n    'talking-heads_base':\n        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2',\n}\n\ntfhub_handle_encoder = map_name_to_handle[bert_model_name]\ntfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n\nprint(f'BERT model selected           : {tfhub_handle_encoder}')\nprint(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:58:21.981009Z","iopub.execute_input":"2021-10-18T18:58:21.981328Z","iopub.status.idle":"2021-10-18T18:58:21.998533Z","shell.execute_reply.started":"2021-10-18T18:58:21.981296Z","shell.execute_reply":"2021-10-18T18:58:21.997702Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def build_classifier_model():\n    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n    encoder_inputs = preprocessing_layer(text_input)\n    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n    outputs = encoder(encoder_inputs)\n    net = outputs['pooled_output']\n    net = tf.keras.layers.Dropout(0.1)(net)\n    net = tf.keras.layers.Dense(1, activation= \"sigmoid\" , name='classifier')(net)\n    return tf.keras.Model(text_input, net)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:58:30.501559Z","iopub.execute_input":"2021-10-18T18:58:30.501813Z","iopub.status.idle":"2021-10-18T18:58:30.510830Z","shell.execute_reply.started":"2021-10-18T18:58:30.501784Z","shell.execute_reply":"2021-10-18T18:58:30.510065Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"\n%%time\nmodel = build_classifier_model()\ntf.keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T18:59:11.640064Z","iopub.execute_input":"2021-10-18T18:59:11.640726Z","iopub.status.idle":"2021-10-18T18:59:33.967811Z","shell.execute_reply.started":"2021-10-18T18:59:11.640692Z","shell.execute_reply":"2021-10-18T18:59:33.967018Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nmetrics = tf.metrics.BinaryAccuracy()","metadata":{"execution":{"iopub.status.busy":"2021-10-18T19:03:07.771452Z","iopub.execute_input":"2021-10-18T19:03:07.771772Z","iopub.status.idle":"2021-10-18T19:03:07.787003Z","shell.execute_reply.started":"2021-10-18T19:03:07.771738Z","shell.execute_reply":"2021-10-18T19:03:07.786161Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"epochs = 3\nsteps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\nnum_train_steps = steps_per_epoch * epochs\nnum_warmup_steps = int(0.1*num_train_steps)\n\ninit_lr = 3e-5\noptimizer = optimization.create_optimizer(init_lr=init_lr,\n                                          num_train_steps=num_train_steps,\n                                          num_warmup_steps=num_warmup_steps,\n                                          optimizer_type='adamw')","metadata":{"execution":{"iopub.status.busy":"2021-10-18T19:04:11.199642Z","iopub.execute_input":"2021-10-18T19:04:11.199901Z","iopub.status.idle":"2021-10-18T19:04:11.207184Z","shell.execute_reply.started":"2021-10-18T19:04:11.199871Z","shell.execute_reply":"2021-10-18T19:04:11.206373Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=optimizer,\n                         loss=loss,\n                         metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T19:04:12.191850Z","iopub.execute_input":"2021-10-18T19:04:12.192534Z","iopub.status.idle":"2021-10-18T19:04:12.201929Z","shell.execute_reply.started":"2021-10-18T19:04:12.192498Z","shell.execute_reply":"2021-10-18T19:04:12.201227Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"print(f'Training model with {tfhub_handle_encoder}')\n#history = classifier_model.fit(x=train_ds, validation_data=valid_ds, epochs=epochs)\nhistory = model.fit(x=train_ds, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T19:04:17.053439Z","iopub.execute_input":"2021-10-18T19:04:17.054034Z","iopub.status.idle":"2021-10-18T19:10:42.883231Z","shell.execute_reply.started":"2021-10-18T19:04:17.053983Z","shell.execute_reply":"2021-10-18T19:10:42.882490Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"#Predict valid data\nprobs_valid = model.predict(X_valid[\"text_lemma\"]) \nthreshold = 0.4\npreds_valid = np.where(probs_valid[:,] > threshold, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T19:15:31.739936Z","iopub.execute_input":"2021-10-18T19:15:31.740621Z","iopub.status.idle":"2021-10-18T19:15:37.643624Z","shell.execute_reply.started":"2021-10-18T19:15:31.740585Z","shell.execute_reply":"2021-10-18T19:15:37.642875Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"from mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Plot confusion matrix\ncm  = confusion_matrix(y_valid.target, preds_valid)\nclassif_report = classification_report(y_valid.target, preds_valid)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Non-Disaster', 'Disaster'], fontsize=16)\nplt.yticks(range(2), ['Non-Disaster', 'Disaster'], fontsize=16)\nplt.xlabel('Predicted Label',fontsize=18)\nplt.ylabel('True Label',fontsize=18)\nplt.show()\n\n\nprint(classif_report)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-18T19:16:48.319590Z","iopub.execute_input":"2021-10-18T19:16:48.319841Z","iopub.status.idle":"2021-10-18T19:16:48.482777Z","shell.execute_reply.started":"2021-10-18T19:16:48.319813Z","shell.execute_reply":"2021-10-18T19:16:48.481951Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"#Predict on test\nprobs_test = model.predict(df_test[\"text_lemma\"]) \nthreshold = 0.4\npreds_test = np.where(probs_test[:,] > threshold, 1, 0)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T19:17:45.735761Z","iopub.execute_input":"2021-10-18T19:17:45.736619Z","iopub.status.idle":"2021-10-18T19:18:26.730591Z","shell.execute_reply.started":"2021-10-18T19:17:45.736570Z","shell.execute_reply":"2021-10-18T19:18:26.729725Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"#make submission file\ndf_submission[\"target\"]=preds_test\ndf_submission.to_csv('submission.csv', index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-18T19:18:52.042611Z","iopub.execute_input":"2021-10-18T19:18:52.043462Z","iopub.status.idle":"2021-10-18T19:18:52.056784Z","shell.execute_reply.started":"2021-10-18T19:18:52.043423Z","shell.execute_reply":"2021-10-18T19:18:52.056036Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}